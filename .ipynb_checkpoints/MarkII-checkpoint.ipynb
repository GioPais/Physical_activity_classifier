{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3: Redes Neuronales Artificiales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaci√≥n de DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "mean:[0.027909902,-0.99785272,-0.001931412,1.506938,1.265255174,-0.94328015,-25.469129999999996,-42.301207999999995,3.738514626]\n",
      "var:[0.005201803730236396,0.009767228441801602,0.005743996674838256,0.002185380396,1.8675492931219797,1.5136131910446715,1.4289264010999991,0.3879815887359995,7.833129032443055]\n",
      "H:[-inf,6.209660310234993,-inf,6.214115146148642,-inf,-inf,6.213506664555782,6.214499757896755,-inf]\n",
      "K:[2.0797710132964573,0.1562451071595672,0.5480248396315996,5.056218202195623,0.11687826738541052,-1.1937164304285248,0.6256594305287222,1.8258631761652477,-0.6564941703619174]\n",
      "EE:[1.0038016560590113,2.671732106662758,49.61547449898034]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sci\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DIR='C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset'\n",
    "df= pd.read_csv(DIR+'/S01/bike1.csv',header=None)\n",
    "print(type(df))\n",
    "data=df.as_matrix()\n",
    "d_size=len(data)\n",
    "#print(data)\n",
    "final_data=[]\n",
    "#Extract data for sensor\n",
    "sensors=[[],[],[],[],[],[],[],[],[]]\n",
    "for i in range(0,d_size):\n",
    "    for j in range(0,9):\n",
    "        sensors[j].append(data[i][j])\n",
    "\n",
    "#---------------------mean-----------------------\n",
    "ms=[]\n",
    "for j in range(0,9):\n",
    "    mean=np.mean(sensors[j])\n",
    "    final_data.append(mean)\n",
    "    ms.append(mean)\n",
    "print('mean:[{},{},{},{},{},{},{},{},{}]'.format(ms[0],ms[1],ms[2],ms[3],ms[4],ms[5],ms[6],ms[7],ms[8]))\n",
    "#---------------------Var------------------------    \n",
    "vs=[]\n",
    "for j in range(0,9):\n",
    "    var=np.var(sensors[j])\n",
    "    final_data.append(var)\n",
    "    vs.append(var)\n",
    "print('var:[{},{},{},{},{},{},{},{},{}]'.format(vs[0],vs[1],vs[2],vs[3],vs[4],vs[5],vs[6],vs[7],vs[8]))\n",
    "#-------------------Entropy----------------------\n",
    "Hs=[]\n",
    "for j in range(0,9):\n",
    "    H=sci.stats.entropy(sensors[j])\n",
    "    #final_data.append(H)\n",
    "    Hs.append(H)\n",
    "print('H:[{},{},{},{},{},{},{},{},{}]'.format(Hs[0],Hs[1],Hs[2],Hs[3],Hs[4],Hs[5],Hs[6],Hs[7],Hs[8]))\n",
    "#-------------------Kurtosis----------------------\n",
    "Ks=[]\n",
    "for j in range(0,9):\n",
    "    K=sci.stats.kurtosis(sensors[j])\n",
    "    final_data.append(K)\n",
    "    Ks.append(K)\n",
    "print('K:[{},{},{},{},{},{},{},{},{}]'.format(Ks[0],Ks[1],Ks[2],Ks[3],Ks[4],Ks[5],Ks[6],Ks[7],Ks[8]))\n",
    "#-------------------Kurtosis----------------------\n",
    "EEs=[]\n",
    "for j in range(0,3):\n",
    "    EE=0\n",
    "    for i in range(0,d_size):\n",
    "        EE+=(1/d_size)*np.sqrt(sensors[0+j*3][i]*sensors[0+j*3][i]+sensors[1+j*3][i]*sensors[1+j*3][i]+sensors[2+j*3][i]*sensors[2+j*3][i])\n",
    "    #EE=sci.stats.kurtosis(sensors[j])\n",
    "    #final_data.append(K)\n",
    "    EEs.append(EE)\n",
    "print('EE:[{},{},{}]'.format(EEs[0],EEs[1],EEs[2]))\n",
    "    \n",
    "#print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S02/gymbike1.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S02/gymbike2.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S02/gymbike3.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S02/gymbike4.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S03/treadmill3.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S04/bike1.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S04/bike2.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S04/bike3.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S04/bike4.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S06/bike1.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S06/bike2.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S06/bike3.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S06/bike4.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S07/bike1.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S07/bike2.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S07/bike3.csv path doesn t exist\n",
      "C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset/S07/bike4.csv path doesn t exist\n",
      "Cantidad de datos: 307\n",
      "Cantidad de caracteristicas: 28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DIR='C:\\Projects\\Physical_activity_classifier/Smartphone_Dataset'\n",
    "data= pd.read_csv(DIR+'/S01/bike1.csv',header=None)\n",
    "#print(data)\n",
    "\n",
    "x=[]\n",
    "for suj in range(1,10):#######################10\n",
    "    for act in range(0,9):###################9\n",
    "        Activities=['bike','climbing','descending','gymbike','jumping','running','standing','treadmill','walking']\n",
    "        for k in range(1,5):\n",
    "            path=DIR+'/S0'+str(suj)+'/'+Activities[act]+str(k)+'.csv'\n",
    "            try:\n",
    "                #Activity[j].append(pd.read_csv(path,header=None))\n",
    "                df=pd.read_csv(path,header=None)\n",
    "                \n",
    "                #print(type(df))\n",
    "                data=df.as_matrix()\n",
    "                d_size=len(data)\n",
    "                #print(data)\n",
    "                final_data=[]\n",
    "                #Extract data for sensor\n",
    "                sensors=[[],[],[],[],[],[],[],[],[]]\n",
    "                for i in range(0,d_size):\n",
    "                    for j in range(0,9):\n",
    "                        sensors[j].append(data[i][j])\n",
    "\n",
    "                #---------------------mean-----------------------\n",
    "                ms=[]\n",
    "                for j in range(0,9):\n",
    "                    mean=np.mean(sensors[j])\n",
    "                    final_data.append(mean)\n",
    "                    ms.append(mean)\n",
    "                #print('mean:[{},{},{},{},{},{},{},{},{}]'.format(ms[0],ms[1],ms[2],ms[3],ms[4],ms[5],ms[6],ms[7],ms[8]))\n",
    "                #---------------------Var------------------------    \n",
    "                vs=[]\n",
    "                for j in range(0,9):\n",
    "                    var=np.var(sensors[j])\n",
    "                    final_data.append(var)\n",
    "                    vs.append(var)\n",
    "                #print('var:[{},{},{},{},{},{},{},{},{}]'.format(vs[0],vs[1],vs[2],vs[3],vs[4],vs[5],vs[6],vs[7],vs[8]))\n",
    "                #-------------------Entropy----------------------\n",
    "                Hs=[]\n",
    "                for j in range(0,9):\n",
    "                    H=sci.stats.entropy(sensors[j])\n",
    "                    #final_data.append(H)\n",
    "                    Hs.append(H)\n",
    "                #print('H:[{},{},{},{},{},{},{},{},{}]'.format(Hs[0],Hs[1],Hs[2],Hs[3],Hs[4],Hs[5],Hs[6],Hs[7],Hs[8]))\n",
    "                #-------------------Kurtosis----------------------\n",
    "                Ks=[]\n",
    "                for j in range(0,9):\n",
    "                    K=sci.stats.kurtosis(sensors[j])\n",
    "                    final_data.append(K)\n",
    "                    Ks.append(K)\n",
    "                #print('K:[{},{},{},{},{},{},{},{},{}]'.format(Ks[0],Ks[1],Ks[2],Ks[3],Ks[4],Ks[5],Ks[6],Ks[7],Ks[8]))\n",
    "                #-------------------Kurtosis----------------------\n",
    "                EEs=[]\n",
    "                for j in range(0,3):\n",
    "                    EE=0\n",
    "                    for i in range(0,d_size):\n",
    "                        EE+=(1/d_size)*np.sqrt(sensors[0+j*3][i]*sensors[0+j*3][i]+sensors[1+j*3][i]*sensors[1+j*3][i]+sensors[2+j*3][i]*sensors[2+j*3][i])\n",
    "                    #EE=sci.stats.kurtosis(sensors[j])\n",
    "                    #final_data.append(K)\n",
    "                    EEs.append(EE)\n",
    "                #print('K:[{},{},{}]'.format(EEs[0],EEs[1],EEs[2]))\n",
    "                \n",
    "                final_data.append(act)\n",
    "                #print(final_data)\n",
    "                x.append(final_data)\n",
    "                \n",
    "            except FileNotFoundError :\n",
    "                print(path+' path doesn t exist')\n",
    "        \n",
    "    \n",
    "print('Cantidad de datos: {}'.format(len(x)))\n",
    "print('Cantidad de caracteristicas: {}'.format(len(x[0])))\n",
    "#print('Datos por actividad: [{},{},{},{},{},{},{},{},{}]'.format(len(Activity[0]),len(Activity[1]),len(Activity[2]),len(Activity[3]),len(Activity[4]),len(Activity[5]),len(Activity[6]),len(Activity[7]),len(Activity[8])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos por sujeto: 500\n",
      "Cantidad de actividades: 9\n",
      "Datos por actividad: [12000,18000,18000,16000,18000,18000,18000,17500,18000]\n"
     ]
    }
   ],
   "source": [
    "print('Datos por sujeto: {}'.format(len(Activity[0][0])))\n",
    "#print('Datos por sujeto: {}'.format(len(Activity[4][3])))\n",
    "#print('Datos por sujeto: {}'.format(len(Activity[6][2])))\n",
    "\n",
    "act_df=[]\n",
    "for i in range(0,9):\n",
    "    act_df.append(pd.concat(Activity[i], ignore_index=True))\n",
    "    \n",
    "print('Cantidad de actividades: {}'.format(len(act_df)))\n",
    "print('Datos por actividad: [{},{},{},{},{},{},{},{},{}]'.format(len(act_df[0]),len(act_df[1]),len(act_df[2]),len(act_df[3]),len(act_df[4]),len(act_df[5]),len(act_df[6]),len(act_df[7]),len(act_df[8])))\n",
    "#print('Features: {}'.format(act_df[0][0]))\n",
    "#print(type(act_df[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_train=[[],[],[],[],[],[],[],[],[]]\n",
    "act_val=[[],[],[],[],[],[],[],[],[]]\n",
    "act_test=[[],[],[],[],[],[],[],[],[]]\n",
    "for i in range(0,9):\n",
    "    df_size=len(act_df[i])\n",
    "    #print((df_size*60)//100)\n",
    "    D=act_df[i].as_matrix()\n",
    "    act_train[i]=D[0:(df_size*60)//100]\n",
    "    aux=D[(df_size*60)//100:df_size]\n",
    "    aux_size=len(aux)\n",
    "    act_val[i]=aux[0:(aux_size*50)//100]\n",
    "    act_test[i]=aux[(aux_size*50)//100:aux_size]\n",
    "\n",
    "print('Entrenamiento: [{},{},{},{},{},{},{},{},{}]'.format(len(act_train[0]),len(act_train[1]),len(act_train[2]),len(act_train[3]),len(act_train[4]),len(act_train[5]),len(act_train[6]),len(act_train[7]),len(act_train[8])))\n",
    "print('Validacion: [{},{},{},{},{},{},{},{},{}]'.format(len(act_val[0]),len(act_val[1]),len(act_val[2]),len(act_val[3]),len(act_val[4]),len(act_val[5]),len(act_val[6]),len(act_val[7]),len(act_val[8])))\n",
    "print('Prueba: [{},{},{},{},{},{},{},{},{}]'.format(len(act_test[0]),len(act_test[1]),len(act_test[2]),len(act_test[3]),len(act_test[4]),len(act_test[5]),len(act_test[6]),len(act_test[7]),len(act_test[8])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=100\n",
    "p=True\n",
    "p2=True\n",
    "x_train=[[],[],[],[],[],[],[],[],[]]\n",
    "for i in range(0,9):\n",
    "    n_step=len(act_train[i])//l\n",
    "    for j in range(0,n_step):\n",
    "        data=act_train[i][j*l:(j+1)*l]\n",
    "        #print(len(data))\n",
    "        xi=[]\n",
    "        ############################mean################################\n",
    "        mean=[0,0,0,0,0,0,0,0,0]\n",
    "        for k in range(0,l):\n",
    "            for c in range(0,9):\n",
    "                mean[c]+=(data[k][c])/100\n",
    "        if p:\n",
    "            print(mean)\n",
    "            p=False\n",
    "        x_train[i].append(mean)\n",
    "        #############################var################################\n",
    "        var=[0,0,0,0,0,0,0,0,0]\n",
    "        for k in range(0,l):\n",
    "            for c in range(0,9):\n",
    "                var[c]+=(data[k][c]-mean[c])*(data[k][c]-mean[c])/100\n",
    "        if p2:\n",
    "            print(var)\n",
    "            p2=False\n",
    "        x_train[i].append(var)\n",
    "        ################################################################\n",
    "    #print(x_train[i])\n",
    "    \n",
    "print('Entrenamiento: [{},{},{},{},{},{},{},{},{}]'.format(len(x_train[0]),len(x_train[1]),len(x_train[2]),len(x_train[3]),len(x_train[4]),len(x_train[5]),len(x_train[6]),len(x_train[7]),len(x_train[8])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=100\n",
    "p=True\n",
    "p2=True\n",
    "x_train=[[],[],[],[],[],[],[],[],[]]\n",
    "for i in range(0,1): #Activities\n",
    "    n_step=len(act_train[i])//l\n",
    "    print('numero de sub datos: {}'.format(n_step))\n",
    "    for j in range(0,n_step): #sub_data\n",
    "        data=act_train[i][j*l:(j+1)*l]\n",
    "        #print(len(data))\n",
    "        xi=[[],[],[],[],[],[],[],[],[]]\n",
    "        \n",
    "        for k in range(0,l):\n",
    "            for sensor in range(0,9):\n",
    "                xi[sensor].append(data[k][sensor])\n",
    "            \n",
    "        print('sensor: [{},{},{},{},{},{},{},{},{}]'.format(len(xi[0]),len(xi[1]),len(xi[2]),len(xi[3]),len(xi[4]),len(xi[5]),len(xi[6]),len(xi[7]),len(xi[8])))\n",
    "        \n",
    "        ############################mean################################\n",
    "        #mean=[0,0,0,0,0,0,0,0,0]\n",
    "        for k in range(0,l):\n",
    "            for sensor in range(0,9):\n",
    "                mean=np.mean(xi[sensor])\n",
    "                xtrain[i].appe\n",
    "        if p:\n",
    "            print(mean)\n",
    "            p=False\n",
    "        x_train[i].append(mean)\n",
    "        #############################var################################\n",
    "        \n",
    "        ################################################################\n",
    "    #print(x_train[i])\n",
    "    \n",
    "print('Entrenamiento: [{},{},{},{},{},{},{},{},{}]'.format(len(x_train[0]),len(x_train[1]),len(x_train[2]),len(x_train[3]),len(x_train[4]),len(x_train[5]),len(x_train[6]),len(x_train[7]),len(x_train[8])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
